{"version":3,"sources":["pages/tensorflow mileage/tensorflow.mileage.function.js","pages/homepage/homepage.jsx","components/spinner/spinner.component.jsx","pages/tensorflow handwriting/tensorflow.handwriting.functions.js","pages/tensorflow mileage/tensorflow.mileage.jsx","pages/tensorflow handwriting/data.js","pages/tensorflow handwriting/tensorflow.handwriting.jsx","pages/tensorflow baseball/tensorflow.baseball.jsx","App.js","index.js"],"names":["model","tensorData","Homepage","className","to","Spinner","prepareTheModel","a","getData","data","createModel","convertToTensor","inputs","labels","trainModel","makePrediction","userInput","inputMin","inputMax","labelMin","labelMax","num","dataSync","predict","tf","mul","sub","add","toFixed","fetch","carsDataResponse","json","carsData","cleaned","map","car","mpg","Miles_per_Gallon","horsepower","Horsepower","filter","dense","inputShape","units","useBias","activation","shuffle","d","inputTensor","length","labelTensor","max","min","div","compile","optimizer","adam","loss","meanSquaredError","metrics","fit","batchSize","epochs","TensorflowMileage","handleSubmit","event","preventDefault","setState","answer","state","number","handleChange","target","name","value","loading","this","onSubmit","type","placeholder","onChange","React","Component","IMAGE_SIZE","NUM_CLASSES","NUM_TRAIN_ELEMENTS","MnistData","shuffledTrainIndex","shuffledTestIndex","img","Image","canvas","document","createElement","ctx","getContext","imgRequest","Promise","resolve","reject","crossOrigin","onload","width","naturalWidth","height","naturalHeight","datasetBytesBuffer","ArrayBuffer","NUM_DATASET_ELEMENTS","chunkSize","i","datasetBytesView","Float32Array","drawImage","imageData","getImageData","j","datasetImages","src","labelsRequest","all","imgResponse","labelsResponse","Uint8Array","arrayBuffer","datasetLabels","datasetimg","trainIndices","createShuffledIndices","testIndices","trainImages","slice","testImages","trainLabels","testLabels","nextBatch","index","batchImagesArray","batchLabelsArray","idx","image","set","label","xs","load","getModel","train","conv2d","kernelSize","filters","strides","kernelInitializer","maxPooling2d","poolSize","flatten","nextTrainBatch","reshape","trainXs","trainYs","nextTestBatch","testXs","testYs","validationData","TensorflowHandwriting","TensorflowBaseball","classname","App","fallback","exact","path","component","ReactDOM","render","StrictMode","basename","process","getElementById"],"mappings":"2XAEIA,EACAC,E,qECgBWC,EAdE,kBACb,sBAAKC,UAAU,WAAf,UACI,cAAC,IAAD,CAAMA,UAAU,0BAA0BC,GAAG,WAA7C,SACI,oBAAID,UAAU,OAAd,iCAEJ,cAAC,IAAD,CAAMA,UAAU,0BAA0BC,GAAG,eAA7C,SACI,oBAAID,UAAU,OAAd,qCAEJ,cAAC,IAAD,CAAMA,UAAU,WAAWC,GAAG,YAA9B,SACI,oBAAID,UAAU,OAAd,4CCHGE,G,OAPC,kBACd,sBAAKF,UAAU,kBAAf,UACE,oBAAIA,UAAU,UAAd,0CACA,qBAAKA,UAAU,2B,sEFFZ,SAAeG,IAAtB,+B,4CAAO,gCAAAC,EAAA,sEAEgBC,IAFhB,cAEGC,EAFH,OAKHT,EAAQU,IAGRT,EAAaU,EAAgBF,GACvBG,EAASX,EAAWW,OACpBC,EAASZ,EAAWY,OAVvB,SAaGC,EAAWd,EAAOY,EAAQC,GAb7B,4C,sBAiBA,SAASE,EAAeC,GAC3B,IAAI,EAA6Cf,EAA3CgB,EAAN,EAAMA,SAAUC,EAAhB,EAAgBA,SAAUC,EAA1B,EAA0BA,SAAUC,EAApC,EAAoCA,SAEpC,GAAGJ,EAAY,GAAKA,EAAY,IAC5B,OAAO,EAEX,IAAMK,GAAOL,EAAYC,EAASK,aAAeJ,EAASI,WAAaL,EAASK,YAMhF,OAJctB,EAAMuB,QAAQC,IAAY,CAACH,GAAM,CAAC,EAAG,KAEzBI,IAAIL,EAASM,IAAIP,IAAWQ,IAAIR,GAEvCG,WAAW,GAAGM,QAAQ,G,SAK9BpB,I,2EAAf,gCAAAD,EAAA,sEACmCsB,MAAM,+DADzC,cACUC,EADV,gBAE2BA,EAAiBC,OAF5C,cAEUC,EAFV,OAGUC,EAAUD,EAASE,KAAI,SAAAC,GAAG,MAAK,CACjCC,IAAKD,EAAIE,iBACTC,WAAYH,EAAII,eAEnBC,QAAO,SAAAL,GAAG,OAAgB,MAAXA,EAAIC,KAAiC,MAAlBD,EAAIG,cAP3C,kBASWL,GATX,4C,sBAaA,SAASvB,IAEL,IAAMV,EAAQwB,MAWd,OARAxB,EAAM2B,IAAIH,IAAUiB,MAAM,CAACC,WAAY,CAAC,GAAIC,MAAO,GAAIC,SAAS,KAEhE5C,EAAM2B,IAAIH,IAAUiB,MAAM,CAACE,MAAO,GAAIE,WAAY,aAClD7C,EAAM2B,IAAIH,IAAUiB,MAAM,CAACE,MAAO,GAAIE,WAAY,aAGlD7C,EAAM2B,IAAIH,IAAUiB,MAAM,CAACE,MAAO,EAAGC,SAAS,KAEvC5C,EAUX,SAASW,EAAgBF,GAIrB,OAAOe,KAAQ,WAEXA,IAAQsB,QAAQrC,GAGhB,IAAMG,EAASH,EAAKyB,KAAI,SAAAa,GAAC,OAAIA,EAAET,cACzBzB,EAASJ,EAAKyB,KAAI,SAAAa,GAAC,OAAIA,EAAEX,OAEzBY,EAAcxB,IAAYZ,EAAQ,CAACA,EAAOqC,OAAQ,IAClDC,EAAc1B,IAAYX,EAAQ,CAACA,EAAOoC,OAAQ,IAGlD/B,EAAW8B,EAAYG,MACvBlC,EAAW+B,EAAYI,MACvBhC,EAAW8B,EAAYC,MACvBhC,EAAW+B,EAAYE,MAK7B,MAAO,CACHxC,OAJqBoC,EAAYtB,IAAIT,GAAUoC,IAAInC,EAASQ,IAAIT,IAKhEJ,OAJqBqC,EAAYxB,IAAIP,GAAUkC,IAAIjC,EAASM,IAAIP,IAMhED,WACAD,WACAG,WACAD,e,SAMGL,E,kFAAf,WAA0Bd,EAAOY,EAAQC,GAAzC,SAAAN,EAAA,6DAEIP,EAAMsD,QAAQ,CACVC,UAAW/B,IAASgC,OACpBC,KAAMjC,IAAUkC,iBAChBC,QAAS,CAAC,SAGI,GACH,IATnB,SAWiB3D,EAAM4D,IAAIhD,EAAQC,EAAQ,CACnCgD,UAJc,GAKdC,OAJW,IAKXhB,SAAS,IAdjB,oF,iCG5GI9C,ECkDW+D,E,kDA9Cb,aAAe,IAAD,8BACZ,gBAeFC,aAhBc,uCAgBC,WAAOC,GAAP,SAAA1D,EAAA,sEACP0D,EAAMC,iBADC,OAGb,EAAKC,SAAS,CAAEC,OAAQrD,EAAe,EAAKsD,MAAMC,UAHrC,2CAhBD,wDAsBdC,aAAe,SAACN,GACd,MAAwBA,EAAMO,OAAtBC,EAAR,EAAQA,KAAMC,EAAd,EAAcA,MAEd,EAAKP,SAAL,eAAiBM,EAAOC,KAtBxB,EAAKL,MAAQ,CACXM,SAAS,EACTL,OAAQ,KACRF,OAAQ,GANE,E,4FAUd,sBAAA7D,EAAA,sEACQD,IADR,OAGEsE,KAAKT,SAAS,CAAEQ,SAAS,IAH3B,gD,0EAkBA,WACE,OAAGC,KAAKP,MAAMM,QACL,cAAC,EAAD,IAIP,sBAAKxE,UAAU,oBAAf,UACI,0EACA,uBAAMA,UAAU,OAAO0E,SAAUD,KAAKZ,aAAtC,UACE,uBAAO7D,UAAU,QAAQsE,KAAK,SAASK,KAAK,SAASC,YAAY,aAAaL,MAAOE,KAAKP,MAAMC,OAAQU,SAAUJ,KAAKL,eACvH,wBAAQpE,UAAU,SAAS2E,KAAK,SAAhC,sBAEF,qBAAI3E,UAAU,aAAd,+BAA8CyE,KAAKP,MAAMD,iB,GAzCnCa,IAAMC,W,OCLhCC,EAAa,IACbC,EAAc,GAGdC,EAAqB,KAcdC,EAAb,WACI,aAAe,oBACXV,KAAKW,mBAAqB,EAC1BX,KAAKY,kBAAoB,EAHjC,+EAMI,mDAAAjF,EAAA,6DAEUkF,EAAM,IAAIC,MACVC,EAASC,SAASC,cAAc,UAChCC,EAAMH,EAAOI,WAAW,MACxBC,EAAa,IAAIC,SAAQ,SAACC,EAASC,GACrCV,EAAIW,YAAc,GAClBX,EAAIY,OAAS,WACTZ,EAAIa,MAAQb,EAAIc,aAChBd,EAAIe,OAASf,EAAIgB,cAEjB,IAAMC,EACF,IAAIC,YAAYC,SAEdC,EAAY,IAClBlB,EAAOW,MAAQb,EAAIa,MACnBX,EAAOa,OAASK,EAEhB,IAAK,IAAIC,EAAI,EAAGA,EAAIF,GAAkCE,IAAK,CACvD,IAAMC,EAAmB,IAAIC,aACzBN,EAAoBI,EAAI3B,EAAa0B,EAAY,EACjD1B,OACJW,EAAImB,UACAxB,EAAK,EAAGqB,EAAID,EAAWpB,EAAIa,MAAOO,EAAW,EAAG,EAAGpB,EAAIa,MACvDO,GAIJ,IAFA,IAAMK,EAAYpB,EAAIqB,aAAa,EAAG,EAAGxB,EAAOW,MAAOX,EAAOa,QAErDY,EAAI,EAAGA,EAAIF,EAAUzG,KAAKwC,OAAS,EAAGmE,IAG3CL,EAAiBK,GAAKF,EAAUzG,KAAS,EAAJ2G,GAAS,IAGtD,EAAKC,cAAgB,IAAIL,aAAaN,GAEtCR,KAERT,EAAI6B,IAtDR,gFAyDMC,EAAgB1F,MAvDtB,gFAcA,SA2CUoE,QAAQuB,IAAI,CAACxB,EAAYuB,IA3CnC,0CA0COE,EA1CP,KA0CoBC,EA1CpB,UA6CyBC,WA7CzB,UA6C0CD,EAAeE,cA7CzD,2BA6CAhD,KAAKiD,cA7CL,oBA8CsBF,WA9CtB,UA8CuCF,EA9CvC,oBA8CA7C,KAAKkD,WA9CL,eAkDAlD,KAAKmD,aAAevG,IAAQwG,sBAAsB3C,GAClDT,KAAKqD,YAAczG,IAAQwG,sBAtELpB,KAyEtBhC,KAAKsD,YACDtD,KAAKyC,cAAcc,MAAM,EAAGhD,QAChCP,KAAKwD,WAAaxD,KAAKyC,cAAcc,MAAMhD,QAC3CP,KAAKyD,YACDzD,KAAKiD,cAAcM,MAAM,EAAG/C,MAChCR,KAAK0D,WACD1D,KAAKiD,cAAcM,MAAM/C,MA5D7B,iDANJ,kFAqEA,SAAevB,GAAY,IAAD,OACtB,OAAOe,KAAK2D,UACR1E,EAAW,CAACe,KAAKsD,YAAatD,KAAKyD,cAAc,WAG7C,OAFA,EAAK9C,oBACA,EAAKA,mBAAqB,GAAK,EAAKwC,aAAa9E,OAC/C,EAAK8E,aAAa,EAAKxC,yBA1E1C,2BA8EA,SAAc1B,GAAY,IAAD,OACrB,OAAOe,KAAK2D,UAAU1E,EAAW,CAACe,KAAKwD,WAAYxD,KAAK0D,aAAa,WAGjE,OAFA,EAAK9C,mBACA,EAAKA,kBAAoB,GAAK,EAAKyC,YAAYhF,OAC7C,EAAKgF,YAAY,EAAKzC,wBAlFrC,uBAsFA,SAAU3B,EAAWpD,EAAM+H,GAIvB,IAHA,IAAMC,EAAmB,IAAIzB,aAAanD,EAAYsB,GAChDuD,EAAmB,IAAIf,WAAW9D,EAAYuB,GAE3C0B,EAAI,EAAGA,EAAIjD,EAAWiD,IAAK,CAChC,IAAM6B,EAAMH,IAENI,EACFnI,EAAK,GAAG0H,MAAMQ,EAAMxD,EAAYwD,EAAMxD,EAAaA,GACvDsD,EAAiBI,IAAID,EAAO9B,EAAI3B,GAEhC,IAAM2D,EACFrI,EAAK,GAAG0H,MAAMQ,EAAMvD,EAAauD,EAAMvD,EAAcA,GACzDsD,EAAiBG,IAAIC,EAAOhC,EAAI1B,GAMhC,MAAO,CAAC2D,GAHGvH,IAAYiH,EAAkB,CAAC5E,EAAWsB,IAGzCtE,OAFGW,IAAYkH,EAAkB,CAAC7E,EAAWuB,SAvGjE,KFdO,SAAe9E,IAAtB,+B,4CAAO,4BAAAC,EAAA,6DACGE,EAAO,IAAI6E,EADd,SAEG7E,EAAKuI,OAFR,cAIHhJ,EAAQiJ,IAJL,SAMGC,EAAMlJ,EAAOS,GANhB,4C,sBAUP,SAASwI,IACL,IAAMjJ,EAAQwB,MASdxB,EAAM2B,IAAIH,IAAU2H,OAAO,CACvBzG,WAAY,CARI,GACC,GACE,GAOnB0G,WAAY,EACZC,QAAS,EACTC,QAAS,EACTzG,WAAY,OACZ0G,kBAAmB,qBAKvBvJ,EAAM2B,IAAIH,IAAUgI,aAAa,CAACC,SAAU,CAAC,EAAG,GAAIH,QAAS,CAAC,EAAG,MAIjEtJ,EAAM2B,IAAIH,IAAU2H,OAAO,CACvBC,WAAY,EACZC,QAAS,GACTC,QAAS,EACTzG,WAAY,OACZ0G,kBAAmB,qBAEvBvJ,EAAM2B,IAAIH,IAAUgI,aAAa,CAACC,SAAU,CAAC,EAAG,GAAIH,QAAS,CAAC,EAAG,MAKjEtJ,EAAM2B,IAAIH,IAAUkI,WAKpB1J,EAAM2B,IAAIH,IAAUiB,MAAM,CACtBE,MAFuB,GAGvB4G,kBAAmB,kBACnB1G,WAAY,aAMhB,IAAMU,EAAY/B,IAASgC,OAO3B,OANAxD,EAAMsD,QAAQ,CACVC,UAAWA,EACXE,KAAM,0BACNE,QAAS,CAAC,cAGP3D,E,SAIIkJ,E,gFAAf,WAAqBlJ,EAAOS,GAA5B,6BAAAF,EAAA,6DACuB,IACK,KACD,IAH3B,EAK+BiB,KAAQ,WAC/B,IAAMuB,EAAItC,EAAKkJ,eAJK,MAKpB,MAAO,CACP5G,EAAEgG,GAAGa,QAAQ,CANO,KAMW,GAAI,GAAI,IACvC7G,EAAElC,WATV,mBAKWgJ,EALX,KAKoBC,EALpB,OAa6BtI,KAAQ,WAC7B,IAAMuB,EAAItC,EAAKsJ,cAXI,KAYnB,MAAO,CACPhH,EAAEgG,GAAGa,QAAQ,CAbM,IAaW,GAAI,GAAI,IACtC7G,EAAElC,WAjBV,mBAaWmJ,EAbX,KAamBC,EAbnB,uBAqBWjK,EAAM4D,IAAIiG,EAASC,EAAS,CAC/BjG,UArBe,IAsBfqG,eAAgB,CAACF,EAAQC,GACzBnG,OAAQ,GACRhB,SAAS,KAzBjB,4C,iCG3CeqH,E,kDA3Bb,aAAe,IAAD,8BACZ,gBAEK9F,MAAQ,CACXM,SAAS,GAJC,E,4FAQd,sBAAApE,EAAA,sEACQD,IADR,OAGEsE,KAAKT,SAAS,CAAEQ,SAAS,IAH3B,gD,0EAMA,WACE,OAAGC,KAAKP,MAAMM,QACL,cAAC,EAAD,IAIL,qBAAKxE,UAAU,wBAAf,SACI,8D,GAtBwB8E,IAAMC,WCG3BkF,G,OANY,kBACvB,qBAAKC,UAAU,wBAAf,SACI,+DCkBOC,G,OAbH,kBACV,qBAAKnK,UAAU,MAAf,SACE,cAAC,IAAD,UACE,eAAC,WAAD,CAAUoK,SAAU,cAAC,EAAD,IAApB,UACE,cAAC,IAAD,CAAOC,OAAK,EAACC,KAAK,IAAIC,UAAWxK,IACjC,cAAC,IAAD,CAAOuK,KAAK,WAAWC,UAAW3G,IAClC,cAAC,IAAD,CAAO0G,KAAK,eAAeC,UAAWP,IACtC,cAAC,IAAD,CAAOM,KAAK,YAAYC,UAAWN,aCb3CO,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,IAAD,CAAeC,SAAUC,wBAAzB,SACE,cAAC,EAAD,QAGJnF,SAASoF,eAAe,W","file":"static/js/main.fa64791b.chunk.js","sourcesContent":["import * as tf from '@tensorflow/tfjs';\r\n\r\nvar model;\r\nvar tensorData;\r\n\r\nexport async function prepareTheModel() {\r\n    // Load and plot the original input data that we are going to train on.\r\n    const data = await getData();\r\n\r\n    // Create the model\r\n    model = createModel();\r\n\r\n    // Convert the data to a form we can use for training.\r\n    tensorData = convertToTensor(data);\r\n    const inputs = tensorData.inputs;\r\n    const labels = tensorData.labels;\r\n\r\n    // Train the model\r\n    await trainModel(model, inputs, labels);\r\n}\r\n\r\n// Function to help user make predictions on custom data\r\nexport function makePrediction(userInput) {\r\n    var { inputMin, inputMax, labelMin, labelMax } = tensorData;\r\n\r\n    if(userInput < 1 || userInput > 400) \r\n        return 0;\r\n\r\n    const num = (userInput - inputMin.dataSync()) / (inputMax.dataSync() - inputMin.dataSync());\r\n\r\n    const preds = model.predict(tf.tensor2d([num], [1, 1]));\r\n\r\n    const unNormPreds = preds.mul(labelMax.sub(labelMin)).add(labelMin);\r\n\r\n    return unNormPreds.dataSync()[0].toFixed(2);\r\n}\r\n\r\n// 1. LOAD, FORMAT AND VISUALISE THE INPUT DATA\r\n// Get the car data reduced to just the variables we are interested and cleaned of missing data.\r\nasync function getData() {\r\n    const carsDataResponse = await fetch('https://storage.googleapis.com/tfjs-tutorials/carsData.json');\r\n    const carsData = await carsDataResponse.json();\r\n    const cleaned = carsData.map(car => ({\r\n        mpg: car.Miles_per_Gallon,\r\n        horsepower: car.Horsepower,\r\n    }))\r\n    .filter(car => (car.mpg != null && car.horsepower != null));\r\n    \r\n    return cleaned;\r\n}\r\n\r\n// 2. DEFINE THE MODEL ARCHITECTURE\r\nfunction createModel() {\r\n    // Create a sequential model\r\n    const model = tf.sequential();\r\n\r\n    // Add an input layer\r\n    model.add(tf.layers.dense({inputShape: [1], units: 64, useBias: true}));\r\n\r\n    model.add(tf.layers.dense({units: 32, activation: 'sigmoid'}));\r\n    model.add(tf.layers.dense({units: 32, activation: 'sigmoid'}));\r\n\r\n    // Add an output layer\r\n    model.add(tf.layers.dense({units: 1, useBias: true}));\r\n\r\n    return model;\r\n} \r\n\r\n// 3. PREPARE THE DATA FOR TRAINING\r\n/**\r\n * Convert the input data to tensors that we can use for machine\r\n * learning. We will also do the important best practices of _shuffling_\r\n * the data and _normalizing_ the data\r\n * MPG on the y-axis.\r\n */\r\nfunction convertToTensor(data) {\r\n    // Wrapping these calculations in a tidy will dispose any\r\n    // intermediate tensors.\r\n\r\n    return tf.tidy(() => {\r\n        // Step 1. Shuffle the data\r\n        tf.util.shuffle(data);\r\n    \r\n        // Step 2. Convert data to Tensor\r\n        const inputs = data.map(d => d.horsepower)\r\n        const labels = data.map(d => d.mpg);\r\n    \r\n        const inputTensor = tf.tensor2d(inputs, [inputs.length, 1]);\r\n        const labelTensor = tf.tensor2d(labels, [labels.length, 1]);\r\n    \r\n        //Step 3. Normalize the data to the range 0 - 1 using min-max scaling\r\n        const inputMax = inputTensor.max();\r\n        const inputMin = inputTensor.min();\r\n        const labelMax = labelTensor.max();\r\n        const labelMin = labelTensor.min();\r\n    \r\n        const normalizedInputs = inputTensor.sub(inputMin).div(inputMax.sub(inputMin));\r\n        const normalizedLabels = labelTensor.sub(labelMin).div(labelMax.sub(labelMin));\r\n    \r\n        return {\r\n            inputs: normalizedInputs,\r\n            labels: normalizedLabels,\r\n            // Return the min/max bounds so we can use them later.\r\n            inputMax,\r\n            inputMin,\r\n            labelMax,\r\n            labelMin,\r\n        }\r\n    });\r\n}\r\n\r\n// 4. TRAIN THE MODEL\r\nasync function trainModel(model, inputs, labels) {\r\n    // Prepare the model for training.\r\n    model.compile({\r\n        optimizer: tf.train.adam(),\r\n        loss: tf.losses.meanSquaredError,\r\n        metrics: ['mse'],\r\n    });\r\n    \r\n    const batchSize = 64;\r\n    const epochs = 100;\r\n    \r\n    return await model.fit(inputs, labels, {\r\n        batchSize,\r\n        epochs,\r\n        shuffle: true,\r\n    });\r\n}\r\n","import React from 'react';\r\nimport { Link } from 'react-router-dom';\r\n\r\nimport './homepage.styles.scss';\r\n\r\nconst Homepage = () => (\r\n    <div className=\"homepage\">\r\n        <Link className=\"sections selectSections\" to=\"/mileage\">\r\n            <h1 className=\"name\">Mileage Predictor</h1>\r\n        </Link>\r\n        <Link className=\"sections selectSections\" to=\"/handwriting\">\r\n            <h1 className=\"name\">Handwriting Predictor</h1>\r\n        </Link>\r\n        <Link className=\"sections\" to=\"/baseball\">\r\n            <h1 className=\"name\">Baseball Pitch Predictor</h1>\r\n        </Link>\r\n    </div>\r\n);\r\n\r\nexport default Homepage;","import React from \"react\";\r\n\r\nimport \"./spinner.styles.scss\";\r\n\r\nconst Spinner = () => (\r\n  <div className=\"spinner-overlay\">\r\n    <h1 className=\"heading\">The model is getting trained</h1>\r\n    <div className=\"spinner-container\" />\r\n  </div>\r\n);\r\n\r\nexport default Spinner;","import * as tf from '@tensorflow/tfjs';\r\n\r\nimport {MnistData} from './data.js';\r\n\r\nvar model;\r\n\r\nexport async function prepareTheModel() {  \r\n    const data = new MnistData();\r\n    await data.load();\r\n\r\n    model = getModel();\r\n    \r\n    await train(model, data);\r\n}\r\n\r\n// 2. DEFINE THE MODEL ARCHITECTURE\r\nfunction getModel() {\r\n    const model = tf.sequential();\r\n    \r\n    const IMAGE_WIDTH = 28;\r\n    const IMAGE_HEIGHT = 28;\r\n    const IMAGE_CHANNELS = 1;  \r\n    \r\n    // In the first layer of our convolutional neural network we have \r\n    // to specify the input shape. Then we specify some parameters for \r\n    // the convolution operation that takes place in this layer.\r\n    model.add(tf.layers.conv2d({\r\n        inputShape: [IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS],\r\n        kernelSize: 5,\r\n        filters: 8,\r\n        strides: 1,\r\n        activation: 'relu',\r\n        kernelInitializer: 'varianceScaling'\r\n    }));\r\n    \r\n    // The MaxPooling layer acts as a sort of downsampling using max values\r\n    // in a region instead of averaging.  \r\n    model.add(tf.layers.maxPooling2d({poolSize: [2, 2], strides: [2, 2]}));\r\n    \r\n    // Repeat another conv2d + maxPooling stack. \r\n    // Note that we have more filters in the convolution.\r\n    model.add(tf.layers.conv2d({\r\n        kernelSize: 5,\r\n        filters: 16,\r\n        strides: 1,\r\n        activation: 'relu',\r\n        kernelInitializer: 'varianceScaling'\r\n    }));\r\n    model.add(tf.layers.maxPooling2d({poolSize: [2, 2], strides: [2, 2]}));\r\n    \r\n    // Now we flatten the output from the 2D filters into a 1D vector to prepare\r\n    // it for input into our last layer. This is common practice when feeding\r\n    // higher dimensional data to a final classification output layer.\r\n    model.add(tf.layers.flatten());\r\n    \r\n    // Our last layer is a dense layer which has 10 output units, one for each\r\n    // output class (i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9).\r\n    const NUM_OUTPUT_CLASSES = 10;\r\n    model.add(tf.layers.dense({\r\n        units: NUM_OUTPUT_CLASSES,\r\n        kernelInitializer: 'varianceScaling',\r\n        activation: 'softmax'\r\n    }));\r\n    \r\n    \r\n    // Choose an optimizer, loss function and accuracy metric,\r\n    // then compile and return the model\r\n    const optimizer = tf.train.adam();\r\n    model.compile({\r\n        optimizer: optimizer,\r\n        loss: 'categoricalCrossentropy',\r\n        metrics: ['accuracy'],\r\n    });\r\n    \r\n    return model;\r\n}\r\n\r\n// 3. TRAIN THE MODEL\r\nasync function train(model, data) {    \r\n    const BATCH_SIZE = 512;\r\n    const TRAIN_DATA_SIZE = 5500;\r\n    const TEST_DATA_SIZE = 1000;\r\n    \r\n    const [trainXs, trainYs] = tf.tidy(() => {\r\n        const d = data.nextTrainBatch(TRAIN_DATA_SIZE);\r\n        return [\r\n        d.xs.reshape([TRAIN_DATA_SIZE, 28, 28, 1]),\r\n        d.labels\r\n        ];\r\n    });\r\n    \r\n    const [testXs, testYs] = tf.tidy(() => {\r\n        const d = data.nextTestBatch(TEST_DATA_SIZE);\r\n        return [\r\n        d.xs.reshape([TEST_DATA_SIZE, 28, 28, 1]),\r\n        d.labels\r\n        ];\r\n    });\r\n    \r\n    return model.fit(trainXs, trainYs, {\r\n        batchSize: BATCH_SIZE,\r\n        validationData: [testXs, testYs],\r\n        epochs: 10,\r\n        shuffle: true\r\n    });\r\n} \r\n\r\n// 4. EVALUATE OUR MODEL\r\nfunction doPrediction(model, data, testDataSize = 500) {\r\n    const IMAGE_WIDTH = 28;\r\n    const IMAGE_HEIGHT = 28;\r\n    const testData = data.nextTestBatch(testDataSize);\r\n    const testxs = testData.xs.reshape([testDataSize, IMAGE_WIDTH, IMAGE_HEIGHT, 1]);\r\n    const labels = testData.labels.argMax(-1);\r\n    const preds = model.predict(testxs).argMax(-1);\r\n\r\n    testxs.dispose();\r\n    return [preds, labels];\r\n}\r\n","import React from 'react';\r\n\r\nimport { makePrediction, prepareTheModel } from './tensorflow.mileage.function';\r\nimport Spinner from '../../components/spinner/spinner.component';\r\n\r\nimport './tensorflow.mileage.styles.scss';\r\n\r\nclass TensorflowMileage extends React.Component {    \r\n  constructor() {\r\n    super();\r\n\r\n    this.state = {\r\n      loading: true,\r\n      number: null,\r\n      answer: 0\r\n    }\r\n  }\r\n\r\n  async componentDidMount() {\r\n    await prepareTheModel();\r\n\r\n    this.setState({ loading: false });\r\n  }\r\n\r\n  handleSubmit = async (event) => {\r\n    await event.preventDefault();\r\n\r\n    this.setState({ answer: makePrediction(this.state.number) });\r\n  }\r\n\r\n  handleChange = (event) => {\r\n    const { name, value } = event.target;\r\n\r\n    this.setState({ [name]: value });\r\n  }\r\n\r\n  render() {\r\n    if(this.state.loading) {\r\n      return <Spinner />\r\n    }\r\n\r\n    return (\r\n      <div className='tensorflowmileage'>\r\n          <h1>Predict Miles Per Gallon From Horsepower</h1>\r\n          <form className=\"form\" onSubmit={this.handleSubmit}>\r\n            <input className=\"input\" name=\"number\" type=\"number\" placeholder=\"Horsepower\" value={this.state.number} onChange={this.handleChange} />\r\n            <button className=\"button\" type=\"submit\">Enter</button>\r\n          </form>\r\n          <h1 className=\"prediction\">Miles per Gallon: {this.state.answer}</h1>\r\n      </div>\r\n    )\r\n  }\r\n};\r\n\r\nexport default TensorflowMileage;","import * as tf from '@tensorflow/tfjs';\r\n\r\nconst IMAGE_SIZE = 784;\r\nconst NUM_CLASSES = 10;\r\nconst NUM_DATASET_ELEMENTS = 65000;\r\n\r\nconst NUM_TRAIN_ELEMENTS = 55000;\r\nconst NUM_TEST_ELEMENTS = NUM_DATASET_ELEMENTS - NUM_TRAIN_ELEMENTS;\r\n\r\nconst MNIST_IMAGES_SPRITE_PATH =\r\n    'https://storage.googleapis.com/learnjs-data/model-builder/mnist_images.png';\r\nconst MNIST_LABELS_PATH =\r\n    'https://storage.googleapis.com/learnjs-data/model-builder/mnist_labels_uint8';\r\n\r\n/**\r\n * A class that fetches the sprited MNIST dataset and returns shuffled batches.\r\n *\r\n * NOTE: This will get much easier. For now, we do data fetching and\r\n * manipulation manually.\r\n */\r\nexport class MnistData {\r\n    constructor() {\r\n        this.shuffledTrainIndex = 0;\r\n        this.shuffledTestIndex = 0;\r\n    }\r\n\r\n    async load() {\r\n        // Make a request for the MNIST sprited image.\r\n        const img = new Image();\r\n        const canvas = document.createElement('canvas');\r\n        const ctx = canvas.getContext('2d');\r\n        const imgRequest = new Promise((resolve, reject) => {\r\n            img.crossOrigin = '';\r\n            img.onload = () => {\r\n                img.width = img.naturalWidth;\r\n                img.height = img.naturalHeight;\r\n\r\n                const datasetBytesBuffer =\r\n                    new ArrayBuffer(NUM_DATASET_ELEMENTS * IMAGE_SIZE * 4);\r\n\r\n                const chunkSize = 5000;\r\n                canvas.width = img.width;\r\n                canvas.height = chunkSize;\r\n\r\n                for (let i = 0; i < NUM_DATASET_ELEMENTS / chunkSize; i++) {\r\n                    const datasetBytesView = new Float32Array(\r\n                        datasetBytesBuffer, i * IMAGE_SIZE * chunkSize * 4,\r\n                        IMAGE_SIZE * chunkSize);\r\n                    ctx.drawImage(\r\n                        img, 0, i * chunkSize, img.width, chunkSize, 0, 0, img.width,\r\n                        chunkSize);\r\n\r\n                    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\r\n\r\n                    for (let j = 0; j < imageData.data.length / 4; j++) {\r\n                        // All channels hold an equal value since the image is grayscale, so\r\n                        // just read the red channel.\r\n                        datasetBytesView[j] = imageData.data[j * 4] / 255;\r\n                    }\r\n                }\r\n                this.datasetImages = new Float32Array(datasetBytesBuffer);\r\n\r\n                resolve();\r\n        };\r\n        img.src = MNIST_IMAGES_SPRITE_PATH;\r\n    });\r\n\r\n    const labelsRequest = fetch(MNIST_LABELS_PATH);\r\n    const [imgResponse, labelsResponse] =\r\n        await Promise.all([imgRequest, labelsRequest]);\r\n\r\n    this.datasetLabels = new Uint8Array(await labelsResponse.arrayBuffer());\r\n    this.datasetimg = new Uint8Array(await imgResponse);\r\n\r\n    // Create shuffled indices into the train/test set for when we select a\r\n    // random dataset element for training / validation.\r\n    this.trainIndices = tf.util.createShuffledIndices(NUM_TRAIN_ELEMENTS);\r\n    this.testIndices = tf.util.createShuffledIndices(NUM_TEST_ELEMENTS);\r\n\r\n    // Slice the the images and labels into train and test sets.\r\n    this.trainImages =\r\n        this.datasetImages.slice(0, IMAGE_SIZE * NUM_TRAIN_ELEMENTS);\r\n    this.testImages = this.datasetImages.slice(IMAGE_SIZE * NUM_TRAIN_ELEMENTS);\r\n    this.trainLabels =\r\n        this.datasetLabels.slice(0, NUM_CLASSES * NUM_TRAIN_ELEMENTS);\r\n    this.testLabels =\r\n        this.datasetLabels.slice(NUM_CLASSES * NUM_TRAIN_ELEMENTS);\r\n}\r\n\r\nnextTrainBatch(batchSize) {\r\n    return this.nextBatch(\r\n        batchSize, [this.trainImages, this.trainLabels], () => {\r\n            this.shuffledTrainIndex =\r\n                (this.shuffledTrainIndex + 1) % this.trainIndices.length;\r\n            return this.trainIndices[this.shuffledTrainIndex];\r\n        });\r\n}\r\n\r\nnextTestBatch(batchSize) {\r\n    return this.nextBatch(batchSize, [this.testImages, this.testLabels], () => {\r\n        this.shuffledTestIndex =\r\n            (this.shuffledTestIndex + 1) % this.testIndices.length;\r\n        return this.testIndices[this.shuffledTestIndex];\r\n    });\r\n}\r\n\r\nnextBatch(batchSize, data, index) {\r\n    const batchImagesArray = new Float32Array(batchSize * IMAGE_SIZE);\r\n    const batchLabelsArray = new Uint8Array(batchSize * NUM_CLASSES);\r\n\r\n    for (let i = 0; i < batchSize; i++) {\r\n        const idx = index();\r\n\r\n        const image =\r\n            data[0].slice(idx * IMAGE_SIZE, idx * IMAGE_SIZE + IMAGE_SIZE);\r\n        batchImagesArray.set(image, i * IMAGE_SIZE);\r\n\r\n        const label =\r\n            data[1].slice(idx * NUM_CLASSES, idx * NUM_CLASSES + NUM_CLASSES);\r\n        batchLabelsArray.set(label, i * NUM_CLASSES);\r\n        }\r\n\r\n        const xs = tf.tensor2d(batchImagesArray, [batchSize, IMAGE_SIZE]);\r\n        const labels = tf.tensor2d(batchLabelsArray, [batchSize, NUM_CLASSES]);\r\n\r\n        return {xs, labels};\r\n    }\r\n}","import React from 'react';\r\n\r\nimport { prepareTheModel } from './tensorflow.handwriting.functions';\r\nimport Spinner from '../../components/spinner/spinner.component';\r\n\r\nimport './tensorflow.handwriting.styles.scss';\r\n\r\nclass TensorflowHandwriting extends React.Component {\r\n  constructor() {\r\n    super();\r\n\r\n    this.state = {\r\n      loading: true\r\n    }\r\n  }\r\n\r\n  async componentDidMount() {\r\n    await prepareTheModel();\r\n\r\n    this.setState({ loading: false });\r\n  }\r\n\r\n  render() {\r\n    if(this.state.loading) {\r\n      return <Spinner />\r\n    }\r\n\r\n    return (\r\n        <div className=\"tensorflowhandwriting\">\r\n            <h1>Tensorflow Handwriting</h1>\r\n        </div>\r\n    )\r\n  }\r\n}\r\n\r\nexport default TensorflowHandwriting;","import React from 'react';\r\n\r\nimport './tensorflow.baseball.styles.scss';\r\n\r\nconst TensorflowBaseball = () => (\r\n    <div classname=\"tensorflowhandwriting\">\r\n        <h1>Tensorflow Baseball Pitch</h1>\r\n    </div>\r\n);\r\n\r\nexport default TensorflowBaseball;","import React, { Suspense } from 'react';\nimport { Switch, Route } from 'react-router-dom';\n\nimport Homepage from './pages/homepage/homepage.jsx';\nimport Spinner from './components/spinner/spinner.component.jsx';\nimport TensorflowMileage from './pages/tensorflow mileage/tensorflow.mileage.jsx';\nimport TensorflowHandwriting from './pages/tensorflow handwriting/tensorflow.handwriting.jsx';\nimport TensorflowBaseball from './pages/tensorflow baseball/tensorflow.baseball.jsx';\n\nimport './App.scss';\n\nconst App = () => (\n  <div className=\"App\">\n    <Switch>\n      <Suspense fallback={<Spinner />}>\n        <Route exact path=\"/\" component={Homepage} />\n        <Route path=\"/mileage\" component={TensorflowMileage} />\n        <Route path=\"/handwriting\" component={TensorflowHandwriting} />\n        <Route path=\"/baseball\" component={TensorflowBaseball} />\n      </Suspense>\n    </Switch>\n  </div>\n);\n\nexport default App;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport { BrowserRouter } from 'react-router-dom';\nimport App from './App';\n\nReactDOM.render(\n  <React.StrictMode>\n    <BrowserRouter basename={process.env.PUBLIC_URL}>\n      <App />\n    </BrowserRouter>\n  </React.StrictMode>,\n  document.getElementById('root')\n);"],"sourceRoot":""}